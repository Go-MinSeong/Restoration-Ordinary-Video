{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets in [GOPRO](https://seungjunnah.github.io/Datasets/gopro.html)\n",
    "1. Download GOPRO_Large_all\n",
    "2. Download GOPRO_Large\n",
    "3. mkdir a data folder\n",
    "4. unzip GOPRO_Large_all under data\n",
    "5. unzip GOPRO_Large under data\n",
    "6. root = './data/'  \n",
    "The dataset under root is as follows. \n",
    "* GOPRO_Large_all\n",
    "* GOPRO_Large\n",
    "* GTMMP\n",
    " * train (synthetic blurry frame from GOPRO_Large_all)\n",
    " * test (test from GOPRO_Large)\n",
    " * mmp_train (generate using optical flow from RAFT)\n",
    " * mmp_test (generate using optical flow from RAFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/kms990321/DiffBIR/project/data/frames_color_after'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth MMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical flow from RAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average of adjescent optical flow, back and forth  \n",
    "normalized by the maximum value of one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('core')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0372_07_00/') #7 61\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0372_07_01/') #7 59\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0374_11_00/') #11 116\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0374_11_01/') #11 108\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0374_11_02/') #11 154\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0374_11_03/') #11 125\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0378_13_00/') #13 40\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0379_11_00/') #11 67\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0380_11_00/') #11 121\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0384_11_01/') #11 100\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0384_11_02/') #11 62\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0384_11_03/') #11 86\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0384_11_04/') #11 150\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0385_11_00/') #11 64\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0386_11_00/') #11 107\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0477_11_00/') #11 155\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0857_11_00/') #11 54 \n",
    "pathlist.append('GTMMP/mmp_train/GOPR0868_11_01/') #11 46\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0868_11_02/') #11 64\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0871_11_01/') #11 65\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0881_11_00/') #11 84\n",
    "pathlist.append('GTMMP/mmp_train/GOPR0884_11_00/') #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for name in pathlist:\n",
    "    folder_name = root + name\n",
    "    if os.path.exists(folder_name) is False:\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0384_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0384_11_05/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0385_11_01/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0396_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0410_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0854_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0862_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0868_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0869_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0871_11_00/',11])\n",
    "pathlist.append(['GTMMP/mmp_test/GOPR0881_11_01/',11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for name,frames in pathlist:\n",
    "    folder_name = root + name\n",
    "    if os.path.exists(folder_name) is False:\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "#path to gopro_large_all, frames used to generate a synthetic frame in original gopro dataset\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0372_07_00/',7]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0372_07_01/',7]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_00/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_02/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_03/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0378_13_00/',13]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0379_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0380_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_01/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_02/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_03/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_04/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0385_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0386_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0477_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0857_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0868_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0868_11_02/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0871_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0881_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0884_11_00/',11]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img[None].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for name in pathlist:\n",
    "    path = root + name[0]\n",
    "    print(path)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model',default='raft-things.pth', help=\"restore checkpoint\")\n",
    "    parser.add_argument('--path',default=path, help=\"dataset for evaluation\")\n",
    "    parser.add_argument('--small', action='store_true', help='use small model')\n",
    "    parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "    parser.add_argument('--alternate_corr', action='store_true', help='use efficent correlation implementation')\n",
    "    args = parser.parse_args(args=[])\n",
    "    print(args)\n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "    model = model.module\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    avg_max=torch.tensor([0]).cuda()\n",
    "    with torch.no_grad():\n",
    "        images = glob.glob(os.path.join(args.path, '*.png')) + \\\n",
    "                    glob.glob(os.path.join(args.path, '*.jpg'))\n",
    "        images = sorted(images)\n",
    "        frames = name[1]\n",
    "        for i in range(0,len(images)-frames):\n",
    "            bl_avg=0\n",
    "            for j in range(frames-1):\n",
    "                image1 = load_image(images[i+j])\n",
    "                imagen = load_image(images[i+j+1]) #10\n",
    "        \n",
    "                padder = InputPadder(image1.shape)\n",
    "                image1, imagen = padder.pad(image1, imagen)\n",
    "           \n",
    "                flow_low_1n, flow_up_1n = model(image1, imagen, iters=epochs, test_mode=True)\n",
    "            \n",
    "                bl_1n=torch.sqrt(flow_up_1n[:,0,:,:]**2+flow_up_1n[:,1,:,:]**2)\n",
    "            \n",
    "                if j==0:\n",
    "                    bl_avg += 2*bl_1n\n",
    "                else:\n",
    "                    bl_avg += bl_1n\n",
    "            for j in reversed(range(1,frames)):\n",
    "                image1 = load_image(images[i+j])\n",
    "                imagen = load_image(images[i+j-1]) \n",
    "        \n",
    "                padder = InputPadder(image1.shape)\n",
    "                image1, imagen = padder.pad(image1, imagen)\n",
    "           \n",
    "                flow_low_1n, flow_up_1n = model(image1, imagen, iters=epochs, test_mode=True)\n",
    "            \n",
    "                bl_1n=torch.sqrt(flow_up_1n[:,0,:,:]**2+flow_up_1n[:,1,:,:]**2)\n",
    "            \n",
    "                if j==frames-1:\n",
    "                    bl_avg += 2*bl_1n\n",
    "                else:\n",
    "                    bl_avg += bl_1n\n",
    "            bl=bl_avg.cpu().numpy().squeeze()/2/frames\n",
    "       \n",
    "            save_path=images[i].replace(\"GOPRO_Large_all/train\",\"GTMMP/mmp_train\")\n",
    "        \n",
    "            save_path = save_path.replace(\"png\",\"npy\")\n",
    "            \n",
    "            out = bl/15  #K value\n",
    "            \n",
    "            out[out>1]=1\n",
    "            \n",
    "            out = out.astype(np.float32)\n",
    "            \n",
    "            np.save(save_path, out)\n",
    "        \n",
    "            if np.max(bl)>avg_max:\n",
    "                avg_max=np.max(bl)\n",
    "\n",
    "      \n",
    "    print(avg_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0384_11_00/',11,5])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0384_11_05/',11,15])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0385_11_01/',11,10])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0396_11_00/',11,3])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0410_11_00/',11,19])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0854_11_00/',11,7])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0862_11_00/',11,7])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0868_11_00/',11,5])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0869_11_00/',11,10])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0871_11_00/',11,8])\n",
    "pathlist.append(['GOPRO_Large_all/test/GOPR0881_11_01/',11,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for name in pathlist:\n",
    "    path = name[0]\n",
    "    print(path)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model',default='raft-things.pth', help=\"restore checkpoint\")\n",
    "    parser.add_argument('--path',default=path, help=\"dataset for evaluation\")\n",
    "    parser.add_argument('--small', action='store_true', help='use small model')\n",
    "    parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "    parser.add_argument('--alternate_corr', action='store_true', help='use efficent correlation implementation')\n",
    "    args = parser.parse_args(args=[])\n",
    "    print(args)\n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "    model = model.module\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    avg_max=torch.tensor([0]).cuda()\n",
    "    with torch.no_grad():\n",
    "        images = glob.glob(os.path.join(args.path, '*.png')) + \\\n",
    "                    glob.glob(os.path.join(args.path, '*.jpg'))\n",
    "        images = sorted(images)\n",
    "        frames = name[1]\n",
    "        #for i in range(len(images)-7):\n",
    "        for i in range(0,len(images),frames):\n",
    "            bl_avg=0\n",
    "            for j in range(frames-1):\n",
    "                image1 = load_image(images[i+j])\n",
    "                imagen = load_image(images[i+j+1]) #10\n",
    "        \n",
    "                padder = InputPadder(image1.shape)\n",
    "                image1, imagen = padder.pad(image1, imagen)\n",
    "           \n",
    "                flow_low_1n, flow_up_1n = model(image1, imagen, iters=epochs, test_mode=True)\n",
    "            \n",
    "                bl_1n=torch.sqrt(flow_up_1n[:,0,:,:]**2+flow_up_1n[:,1,:,:]**2)\n",
    "            \n",
    "                #bl_avg=(bl_12+bl_23+bl_34+bl_45+bl_56+bl_67)   #/7.0  +bl_78\n",
    "                if j==0:\n",
    "                    bl_avg += 2*bl_1n\n",
    "                else:\n",
    "                    bl_avg += bl_1n\n",
    "            for j in reversed(range(1,frames)):\n",
    "                #print(1)\n",
    "                image1 = load_image(images[i+j])\n",
    "                imagen = load_image(images[i+j-1]) #10\n",
    "        \n",
    "                padder = InputPadder(image1.shape)\n",
    "                image1, imagen = padder.pad(image1, imagen)\n",
    "           \n",
    "                flow_low_1n, flow_up_1n = model(image1, imagen, iters=epochs, test_mode=True)\n",
    "            \n",
    "                bl_1n=torch.sqrt(flow_up_1n[:,0,:,:]**2+flow_up_1n[:,1,:,:]**2)\n",
    "            \n",
    "                #bl_avg=(bl_12+bl_23+bl_34+bl_45+bl_56+bl_67)   #/7.0  +bl_78\n",
    "                if j==frames-1:\n",
    "                    bl_avg += 2*bl_1n\n",
    "                else:\n",
    "                    bl_avg += bl_1n\n",
    "            bl=bl_avg.cpu().numpy().squeeze()/2/frames\n",
    "       \n",
    "            save_path=images[i].replace(\"GOPRO_Large_all/test\",\"GTMMP/bl_test\")\n",
    "        \n",
    "            save_path = save_path.replace(\"png\",\"npy\")\n",
    "            \n",
    "            out = bl/15  #116 154 31 67\n",
    "            \n",
    "            out[out>1]=1\n",
    "            \n",
    "            #out = out.astype(np.uint8)\n",
    "            \n",
    "            \n",
    "            #out = cv2.equalizeHist(out)\n",
    "        \n",
    "            np.save(save_path, out)\n",
    "        \n",
    "        \n",
    "            if np.max(bl)>avg_max:\n",
    "                avg_max=np.max(bl)\n",
    "\n",
    "      \n",
    "    print(avg_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gerate synthetic blurry frame for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "pathlist.append('GTMMP/train/GOPR0372_07_00/') #7 61\n",
    "pathlist.append('GTMMP/train/GOPR0372_07_01/') #7 59\n",
    "pathlist.append('GTMMP/train/GOPR0374_11_00/') #11 116\n",
    "pathlist.append('GTMMP/train/GOPR0374_11_01/') #11 108\n",
    "pathlist.append('GTMMP/train/GOPR0374_11_02/') #11 154\n",
    "pathlist.append('GTMMP/train/GOPR0374_11_03/') #11 125\n",
    "pathlist.append('GTMMP/train/GOPR0378_13_00/') #13 40\n",
    "pathlist.append('GTMMP/train/GOPR0379_11_00/') #11 67\n",
    "pathlist.append('GTMMP/train/GOPR0380_11_00/') #11 121\n",
    "pathlist.append('GTMMP/train/GOPR0384_11_01/') #11 100\n",
    "pathlist.append('GTMMP/train/GOPR0384_11_02/') #11 62\n",
    "pathlist.append('GTMMP/train/GOPR0384_11_03/') #11 86\n",
    "pathlist.append('GTMMP/train/GOPR0384_11_04/') #11 150\n",
    "pathlist.append('GTMMP/train/GOPR0385_11_00/') #11 64\n",
    "pathlist.append('GTMMP/train/GOPR0386_11_00/') #11 107\n",
    "pathlist.append('GTMMP/train/GOPR0477_11_00/') #11 155\n",
    "pathlist.append('GTMMP/train/GOPR0857_11_00/') #11 54 \n",
    "pathlist.append('GTMMP/train/GOPR0868_11_01/') #11 46\n",
    "pathlist.append('GTMMP/train/GOPR0868_11_02/') #11 64\n",
    "pathlist.append('GTMMP/train/GOPR0871_11_01/') #11 65\n",
    "pathlist.append('GTMMP/train/GOPR0881_11_00/') #11 84\n",
    "pathlist.append('GTMMP/train/GOPR0884_11_00/') #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for name in pathlist:\n",
    "    folder_name = root + name\n",
    "    if os.path.exists(folder_name) is False:\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist=[]\n",
    "#path to gopro_large_all, frames used to generate a synthetic frame in original gopro dataset\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0372_07_00/',7]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0372_07_01/',7]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_00/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_02/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0374_11_03/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0378_13_00/',13]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0379_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0380_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_01/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_02/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_03/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0384_11_04/',11])\n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0385_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0386_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0477_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0857_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0868_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0868_11_02/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0871_11_01/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0881_11_00/',11]) \n",
    "pathlist.append(['GOPRO_Large_all/train/GOPR0884_11_00/',11]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crf.npy file from [GOPRO](https://seungjunnah.github.io/Datasets/reds/crf.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline \n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "crf_path = 'crf.npy'\n",
    "device='cpu'\n",
    "C=3\n",
    "H=720\n",
    "W=1280\n",
    "crf_inv = np.load('crf.npy').squeeze()\n",
    "\n",
    "# 1st order approximation at RGB=250 to regularize extreme responses at RGB>250\n",
    "diff = (crf_inv[251] - crf_inv[249])/2\n",
    "for i in range(251, 256):\n",
    "    crf_inv[i] = crf_inv[i-1] + diff\n",
    "\n",
    "#crf_inv[:,0]=crf_inv[:,1]\n",
    "#crf_inv[:,2]=crf_inv[:,1]\n",
    "x=np.linspace(0,255,256)\n",
    "y=crf_inv[:,0]\n",
    "f1=InterpolatedUnivariateSpline(x,y)\n",
    "f2=InterpolatedUnivariateSpline(y,x)\n",
    "# frame interpolation, etc.\n",
    "\n",
    "for name in pathlist:\n",
    "    path = root + name[0]\n",
    "    images = glob.glob(os.path.join(path, '*.png')) + \\\n",
    "                glob.glob(os.path.join(path, '*.jpg'))\n",
    "    imglist = sorted(images)\n",
    "    frames = name[1]\n",
    "    imgsignal_list=[]\n",
    "    print('buffering')\n",
    "    for k in range(len(imglist)):\n",
    "        img=Image.open(imglist[k])\n",
    "        img=np.array(img)\n",
    "        img=img.reshape(-1)\n",
    "        img_signal=f1(img)\n",
    "        imgsignal_list.append(img_signal)\n",
    "    print('finish buffering')\n",
    "    for i in range(0,len(imglist)-frames):\n",
    "        print(i)\n",
    "        img_blur_signal=0\n",
    "        for j in range(frames):\n",
    "            img_signal=imgsignal_list[i+j]\n",
    "            img_blur_signal += img_signal\n",
    "        img_blur_signal = img_blur_signal/frames\n",
    "        img_blur=f2(img_blur_signal)\n",
    "        img_blur=img_blur.reshape(H,W,C)\n",
    "        \n",
    "        outputname=imglist[i].replace(\"GOPRO_Large_all\",\"GTMMP\")\n",
    "        img_blur=Image.fromarray(img_blur.astype('uint8'))\n",
    "        img_blur.save(outputname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy dir finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "root = 'E:/gopro/'\n",
    "\n",
    "source_path = root+'GOPRO_Large/test'\n",
    "target_path = root+'GTMMP/test'\n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    os.makedirs(target_path)\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    shutil.rmtree(target_path)\n",
    "\n",
    "shutil.copytree(source_path, target_path)\n",
    "print('copy dir finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
